{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4 Analysis: Phenotype Complexity vs Performance\n",
    "\n",
    "This notebook analyzes how ELDER and ontology-only approaches perform across different phenotype complexity levels.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import the required libraries and set up our analysis environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import duckdb\n",
    "\n",
    "# Set up paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RESULTS_DIR = Path(\"../results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "DEFAULT_DATASET = \"normalized_phenopackets_07\"  # Best ELDER performance\n",
    "DB_PATH = DATA_DIR / \"Best_Match_Cosine_all_combined_Elder_vs_Exomiser.db\"\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"Default dataset: {DEFAULT_DATASET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Download Required Database\n\nFirst, let's download the required database from Zenodo if it doesn't exist:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import urllib.request\nimport os\nfrom pathlib import Path\n\nZENODO_URL = \"https://zenodo.org/records/16944913/files/Best_Match_Cosine_all_combined_Elder_vs_Exomiser.db\"\nDB_FILENAME = \"Best_Match_Cosine_all_combined_Elder_vs_Exomiser.db\"\nDB_PATH = DATA_DIR / DB_FILENAME\n\ndef download_with_progress(url, filepath):\n    \"\"\"Download file with progress indicator.\"\"\"\n    def progress_hook(block_num, block_size, total_size):\n        downloaded = block_num * block_size\n        if total_size > 0:\n            percent = min(100, (downloaded * 100) // total_size)\n            mb_downloaded = downloaded / (1024 * 1024)\n            mb_total = total_size / (1024 * 1024)\n            print(f\"\\rDownloading: {percent:3d}% ({mb_downloaded:.1f}/{mb_total:.1f} MB)\", end=\"\", flush=True)\n    \n    urllib.request.urlretrieve(url, filepath, progress_hook)\n    print()\n\nif not DB_PATH.exists():\n    print(f\"Database not found at: {DB_PATH}\")\n    print(f\"Downloading from Zenodo...\")\n    print(f\"URL: {ZENODO_URL}\")\n    \n    DATA_DIR.mkdir(exist_ok=True)\n    \n    try:\n        download_with_progress(ZENODO_URL, DB_PATH)\n        print(f\"Database downloaded successfully!\")\n        print(f\"Saved to: {DB_PATH}\")\n        print(f\"File size: {DB_PATH.stat().st_size / (1024*1024):.1f} MB\")\n        \n    except Exception as e:\n        print(f\"Download failed: {e}\")\n        print(f\"\")\n        print(f\"Manual download instructions:\")\n        print(f\"   1. Visit: https://zenodo.org/records/16944913\")\n        print(f\"   2. Download: {DB_FILENAME}\")\n        print(f\"   3. Place it in: {DATA_DIR}/\")\n        print(f\"\")\n        print(f\"The analysis cannot continue without the database.\")\n        \nelse:\n    print(f\"Database found at: {DB_PATH}\")\n    print(f\"File size: {DB_PATH.stat().st_size / (1024*1024):.1f} MB\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Check Available Datasets\n\nLet's see what normalized datasets are available:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "available_datasets = []\nfor item in DATA_DIR.iterdir():\n    if item.is_dir() and item.name.startswith(\"normalized_phenopackets\"):\n        file_count = len(list(item.glob(\"*.json\")))\n        available_datasets.append((item.name, file_count))\n\nprint(\"Available normalized datasets:\")\nfor dataset, count in sorted(available_datasets):\n    marker = \" (recommended)\" if dataset == DEFAULT_DATASET else \"\"\n    print(f\"  {dataset}: {count} files{marker}\")\n\nprint(f\"\\n{DEFAULT_DATASET} is the default (best ELDER performance)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Analysis Functions\n",
    "\n",
    "Let's define the core analysis functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def query_performance_data(bins, db_path):\n    \"\"\"\n    Query the database for ELDER and Exomiser performance data.\n    \n    Returns:\n        - elder_per_case: Dictionary mapping filenames to ELDER top-1 accuracy\n        - exomiser_per_case: Dictionary mapping filenames to Exomiser top-1 accuracy\n    \"\"\"\n    elder_per_case = {}\n    exomiser_per_case = {}\n    \n    print(f\"\\nQuerying database: {db_path}\")\n    \n    if not db_path.exists():\n        print(f\"Error: Database not found at {db_path}\")\n        print(\"Please download the database from the Zenodo link provided in README.md\")\n        return elder_per_case, exomiser_per_case\n    \n    conn = duckdb.connect(str(db_path))\n    \n    all_files = []\n    for bin_files in bins.values():\n        all_files.extend(bin_files)\n    \n    print(f\"Querying performance data for {len(all_files)} files...\")\n    \n    successful_queries = 0\n    \n    for filename in all_files:\n        query = \"\"\"\n        SELECT Exomiser, cosBMA_ELDER_large3\n        FROM Exomiser_vs_cosBMA_ELDER_large3_disease_rank_comparison\n        WHERE phenopacket = ?\n        \"\"\"\n        \n        try:\n            result = conn.execute(query, [filename]).fetchone()\n            if result:\n                exomiser_rank, elder_rank = result\n                exomiser_top1 = 1 if exomiser_rank == 1 else 0\n                elder_top1 = 1 if elder_rank == 1 else 0\n                \n                exomiser_per_case[filename] = exomiser_top1\n                elder_per_case[filename] = elder_top1\n                successful_queries += 1\n            else:\n                exomiser_per_case[filename] = 0\n                elder_per_case[filename] = 0\n        \n        except Exception as e:\n            print(f\"Database query error for {filename}: {e}\")\n            exomiser_per_case[filename] = 0\n            elder_per_case[filename] = 0\n    \n    conn.close()\n    \n    print(f\"Successfully queried {successful_queries}/{len(all_files)} files\")\n    \n    return elder_per_case, exomiser_per_case"
  },
  {
   "cell_type": "code",
   "source": "def load_dataset_and_bin_by_complexity(dataset_path):\n    \"\"\"\n    Load phenopackets and assign them to complexity bins.\n    \n    Returns:\n        - bins: Dictionary mapping bin names to lists of filenames\n        - file_to_disease: Dictionary mapping filenames to disease IDs\n    \"\"\"\n    bins = {\n        \"1-5\": [],\n        \"10-15\": [],\n        \"15-20\": [],\n        \"20-25\": [],\n        \"25-30\": [],\n        \"30-35\": [],\n        \"35-40\": [],\n        \"40-45\": [],\n        \"45+\": [],\n    }\n    \n    file_to_disease = {}\n    phenotype_counts = []\n    \n    print(f\"Loading dataset from: {dataset_path}\")\n    \n    for json_file in dataset_path.glob(\"*.json\"):\n        try:\n            with open(json_file, 'r') as f:\n                phenopacket = json.load(f)\n            \n            if 'diseases' in phenopacket and phenopacket['diseases']:\n                disease_id = phenopacket['diseases'][0]['term']['id']\n                file_to_disease[json_file.name] = disease_id\n            \n            phenotype_count = 0\n            if 'phenotypicFeatures' in phenopacket:\n                phenotype_count = len(phenopacket['phenotypicFeatures'])\n            \n            phenotype_counts.append(phenotype_count)\n            \n            filename = json_file.name\n            if 1 <= phenotype_count <= 5:\n                bins[\"1-5\"].append(filename)\n            elif 10 <= phenotype_count <= 15:\n                bins[\"10-15\"].append(filename)\n            elif 16 <= phenotype_count <= 20:\n                bins[\"15-20\"].append(filename)\n            elif 21 <= phenotype_count <= 25:\n                bins[\"20-25\"].append(filename)\n            elif 26 <= phenotype_count <= 30:\n                bins[\"25-30\"].append(filename)\n            elif 31 <= phenotype_count <= 35:\n                bins[\"30-35\"].append(filename)\n            elif 36 <= phenotype_count <= 40:\n                bins[\"35-40\"].append(filename)\n            elif 41 <= phenotype_count <= 45:\n                bins[\"40-45\"].append(filename)\n            elif phenotype_count > 45:\n                bins[\"45+\"].append(filename)\n        \n        except Exception as e:\n            print(f\"Error processing {json_file}: {e}\")\n            continue\n    \n    total_binned = sum(len(files) for files in bins.values())\n    print(f\"\\nDataset summary:\")\n    print(f\"  Total files processed: {len(phenotype_counts)}\")\n    print(f\"  Files assigned to bins: {total_binned}\")\n    print(f\"  Average phenotypes per case: {np.mean(phenotype_counts):.1f}\")\n    \n    print(f\"\\nBin distribution:\")\n    for bin_name, files in bins.items():\n        print(f\"  {bin_name}: {len(files)} files\")\n    \n    return bins, file_to_disease",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def calculate_bin_accuracies(bins, elder_per_case, exomiser_per_case):\n    \"\"\"\n    Calculate average top-1 accuracy for each phenotype complexity bin.\n    \n    Returns:\n        - elder_bin_accuracies: Dictionary mapping bin names to ELDER accuracies\n        - exomiser_bin_accuracies: Dictionary mapping bin names to Exomiser accuracies\n    \"\"\"\n    elder_bin_accuracies = {}\n    exomiser_bin_accuracies = {}\n    \n    print(f\"\\nCalculating bin-wise accuracies:\")\n    \n    for bin_name, files in bins.items():\n        if files:\n            elder_accuracies = [elder_per_case.get(f, 0) for f in files]\n            exomiser_accuracies = [exomiser_per_case.get(f, 0) for f in files]\n            \n            elder_bin_accuracies[bin_name] = sum(elder_accuracies) / len(elder_accuracies)\n            exomiser_bin_accuracies[bin_name] = sum(exomiser_accuracies) / len(exomiser_accuracies)\n            \n            print(f\"  Bin {bin_name}: {len(files)} files\")\n            print(f\"    ELDER: {elder_bin_accuracies[bin_name]:.3f}\")\n            print(f\"    Ontology-only: {exomiser_bin_accuracies[bin_name]:.3f}\")\n            print(f\"    Difference: {elder_bin_accuracies[bin_name] - exomiser_bin_accuracies[bin_name]:+.3f}\")\n        else:\n            elder_bin_accuracies[bin_name] = 0\n            exomiser_bin_accuracies[bin_name] = 0\n    \n    return elder_bin_accuracies, exomiser_bin_accuracies"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_figure(elder_bin_accuracies, exomiser_bin_accuracies, dataset_name, save_plots=True):\n",
    "    \"\"\"\n",
    "    Create the comparative bar chart (Figure 4).\n",
    "    \n",
    "    Parameters:\n",
    "        - elder_bin_accuracies: ELDER accuracies by bin\n",
    "        - exomiser_bin_accuracies: Exomiser accuracies by bin\n",
    "        - dataset_name: Name of dataset being analyzed\n",
    "        - save_plots: Whether to save the plots to files\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    bin_names = list(elder_bin_accuracies.keys())\n",
    "    elder_accuracies = list(elder_bin_accuracies.values())\n",
    "    exomiser_accuracies = list(exomiser_bin_accuracies.values())\n",
    "    \n",
    "    x = np.arange(len(bin_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Create bars\n",
    "    bars1 = plt.bar(x - width/2, exomiser_accuracies, width, label='Ontology-only', \n",
    "                   color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "    bars2 = plt.bar(x + width/2, elder_accuracies, width, label='ELDER', \n",
    "                   color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    \n",
    "    # Formatting\n",
    "    plt.xlabel('Phenotype Count Bins', fontsize=12)\n",
    "    plt.ylabel('Average Top-1 Accuracy', fontsize=12)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.xticks(x, bin_names)\n",
    "    plt.legend(fontsize=11)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, accuracy in zip(bars1, exomiser_accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{accuracy:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    for bar, accuracy in zip(bars2, elder_accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{accuracy:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add subtitle with dataset info\n",
    "    plt.figtext(0.5, 0.02, f'Dataset: {dataset_name}', ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    if save_plots:\n",
    "        # Save plots\n",
    "        svg_path = RESULTS_DIR / 'figure_4_phenotype_complexity.svg'\n",
    "        png_path = RESULTS_DIR / 'figure_4_phenotype_complexity.png'\n",
    "        \n",
    "        plt.savefig(svg_path, bbox_inches='tight')\n",
    "        plt.savefig(png_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"\\nðŸ’¾ Plots saved:\")\n",
    "        print(f\"  SVG: {svg_path}\")\n",
    "        print(f\"  PNG: {png_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate overall performance\n",
    "    elder_overall = np.mean(elder_accuracies)\n",
    "    exomiser_overall = np.mean(exomiser_accuracies)\n",
    "    difference = elder_overall - exomiser_overall\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Overall Performance Summary:\")\n",
    "    print(f\"  ELDER average: {elder_overall:.3f}\")\n",
    "    print(f\"  Ontology-only average: {exomiser_overall:.3f}\")\n",
    "    print(f\"  Difference: {difference:+.3f} ({'ELDER better' if difference > 0 else 'Ontology-only better'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Run the Analysis\n\nNow let's run the complete analysis pipeline:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "DATASET_TO_ANALYZE = DEFAULT_DATASET\ndataset_path = DATA_DIR / DATASET_TO_ANALYZE\n\nprint(f\"Running Figure 4 Analysis\")\nprint(f\"Dataset: {DATASET_TO_ANALYZE}\")\nprint(\"=\" * 50)\n\nbins, file_to_disease = load_dataset_and_bin_by_complexity(dataset_path)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "elder_bin_accuracies, exomiser_bin_accuracies = calculate_bin_accuracies(\n    bins, elder_per_case, exomiser_per_case\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "create_figure(elder_bin_accuracies, exomiser_bin_accuracies, DATASET_TO_ANALYZE, save_plots=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "COMPARE_DATASETS = True\n\nif COMPARE_DATASETS and len(available_datasets) > 1:\n    print(\"Comparing multiple datasets...\\n\")\n    \n    dataset_comparisons = []\n    \n    for dataset_name, _ in available_datasets[:3]:\n        print(f\"Analyzing {dataset_name}...\")\n        \n        dataset_path = DATA_DIR / dataset_name\n        bins_temp, _ = load_dataset_and_bin_by_complexity(dataset_path)\n        elder_temp, exomiser_temp = query_performance_data(bins_temp, DB_PATH)\n        elder_acc_temp, exomiser_acc_temp = calculate_bin_accuracies(\n            bins_temp, elder_temp, exomiser_temp\n        )\n        \n        elder_overall = np.mean(list(elder_acc_temp.values()))\n        exomiser_overall = np.mean(list(exomiser_acc_temp.values()))\n        difference = elder_overall - exomiser_overall\n        \n        dataset_comparisons.append({\n            'dataset': dataset_name,\n            'elder_accuracy': elder_overall,\n            'exomiser_accuracy': exomiser_overall,\n            'difference': difference\n        })\n        \n        print(f\"  ELDER: {elder_overall:.3f}, Ontology-only: {exomiser_overall:.3f}, Diff: {difference:+.3f}\\n\")\n    \n    dataset_comparisons.sort(key=lambda x: x['difference'], reverse=True)\n    \n    print(\"Dataset Comparison Summary:\")\n    for i, result in enumerate(dataset_comparisons, 1):\n        marker = \" (recommended)\" if result['dataset'] == DEFAULT_DATASET else \"\"\n        print(f\"{i}. {result['dataset']}: ELDER advantage = {result['difference']:+.3f}{marker}\")\nelse:\n    print(\"Skipping dataset comparison...\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Compare Different Datasets (Optional)\n\nYou can run this cell to quickly compare how different datasets perform:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "COMPARE_DATASETS = True\n\nif COMPARE_DATASETS and len(available_datasets) > 1:\n    print(\"Comparing multiple datasets...\\n\")\n    \n    dataset_comparisons = []\n    \n    for dataset_name, _ in available_datasets[:3]:\n        print(f\"Analyzing {dataset_name}...\")\n        \n        dataset_path = DATA_DIR / dataset_name\n        bins_temp, _ = load_dataset_and_bin_by_complexity(dataset_path)\n        elder_temp, exomiser_temp = query_performance_data(bins_temp, DB_PATH)\n        elder_acc_temp, exomiser_acc_temp = calculate_bin_accuracies(\n            bins_temp, elder_temp, exomiser_temp\n        )\n        \n        elder_overall = np.mean(list(elder_acc_temp.values()))\n        exomiser_overall = np.mean(list(exomiser_acc_temp.values()))\n        difference = elder_overall - exomiser_overall\n        \n        dataset_comparisons.append({\n            'dataset': dataset_name,\n            'elder_accuracy': elder_overall,\n            'exomiser_accuracy': exomiser_overall,\n            'difference': difference\n        })\n        \n        print(f\"  ELDER: {elder_overall:.3f}, Ontology-only: {exomiser_overall:.3f}, Diff: {difference:+.3f}\\n\")\n    \n    dataset_comparisons.sort(key=lambda x: x['difference'], reverse=True)\n    \n    print(\"Dataset Comparison Summary:\")\n    for i, result in enumerate(dataset_comparisons, 1):\n        marker = \" (recommended)\" if result['dataset'] == DEFAULT_DATASET else \"\"\n        print(f\"{i}. {result['dataset']}: ELDER advantage = {result['difference']:+.3f}{marker}\")\nelse:\n    print(\"Skipping dataset comparison...\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}